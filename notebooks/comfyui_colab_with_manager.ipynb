{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaaaaaaaaa"
      },
      "source": [
        "Git clone the repo and install the requirements. (ignore the pip errors about protobuf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bbbbbbbbbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fab2032-961a-4eb0-d84f-bc3ebd3fe735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "/\n",
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n",
            "-= Initial setup ComfyUI =-\n",
            "Cloning into 'ComfyUI'...\n",
            "remote: Enumerating objects: 21095, done.\u001b[K\n",
            "remote: Counting objects: 100% (185/185), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 21095 (delta 145), reused 98 (delta 98), pack-reused 20910 (from 5)\u001b[K\n",
            "Receiving objects: 100% (21095/21095), 71.23 MiB | 14.17 MiB/s, done.\n",
            "Resolving deltas: 100% (14008/14008), done.\n",
            "Updating files: 100% (468/468), done.\n",
            "/content/drive/MyDrive/ComfyUI\n",
            "-= Updating ComfyUI =-\n",
            "Already up to date.\n",
            "-= Install dependencies =-\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.33.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.7.9)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting torchsde\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.11/dist-packages (from torchsde) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from torchsde) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from torchsde) (2.6.0+cu124)\n",
            "Collecting trampoline>=0.1.2 (from torchsde)\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->torchsde) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->torchsde) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->torchsde) (3.0.2)\n",
            "Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: trampoline, torchsde\n",
            "Successfully installed torchsde-0.2.6 trampoline-0.1.2\n",
            "/content/drive/MyDrive/ComfyUI/custom_nodes\n",
            "-= Initial setup ComfyUI-Manager =-\n",
            "Cloning into 'ComfyUI-Manager'...\n",
            "remote: Enumerating objects: 22073, done.\u001b[K\n",
            "remote: Counting objects: 100% (992/992), done.\u001b[K\n",
            "remote: Compressing objects: 100% (382/382), done.\u001b[K\n",
            "remote: Total 22073 (delta 799), reused 630 (delta 610), pack-reused 21081 (from 3)\u001b[K\n",
            "Receiving objects: 100% (22073/22073), 46.81 MiB | 17.33 MiB/s, done.\n",
            "Resolving deltas: 100% (16279/16279), done.\n",
            "/content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "Your configuration specifies to merge with the ref 'refs/heads/main'\n",
            "from the remote, but no such ref was fetched.\n",
            "/content/drive/MyDrive/ComfyUI\n",
            "-= Install custom nodes dependencies =-\n",
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.11/dist-packages (3.1.44)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython) (5.0.2)\n",
            "\n",
            "\u001b[1;33mWARN: The `COMFYUI_PATH` environment variable is not set. Assuming \u001b[0m\n",
            "\u001b[1;33m`custom_nodes/ComfyUI-Manager/..\u001b[0m\u001b[1;33m/../\u001b[0m\u001b[1;33m` as the ComfyUI path.\u001b[0m\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------\n",
            "Restoring \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m/\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m: \u001b[35m/content/drive/MyDrive/ComfyUI/custom_nodes/\u001b[0m\u001b[95mComfyUI-Manager\u001b[0m\n",
            "Install: pip packages\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \n",
            "\u001b[32m'GitPython'\u001b[0m\u001b[1m]\u001b[0m\n",
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.11/dist-packages (3.1.44)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython) (5.0.2)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \n",
            "\u001b[32m'PyGithub'\u001b[0m\u001b[1m]\u001b[0m\n",
            "Collecting PyGithub\n",
            "  Downloading PyGithub-2.6.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pynacl>=1.4.0 (from PyGithub)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub) (2.32.3)\n",
            "Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (2.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub) (4.14.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub) (2.4.0)\n",
            "Collecting Deprecated (from PyGithub)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pynacl>=1.4.0->PyGithub) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub) (2025.7.9)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from Deprecated->PyGithub) (1.17.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.22)\n",
            "Downloading PyGithub-2.6.1-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: Deprecated, pynacl, PyGithub\n",
            "Successfully installed Deprecated-1.2.18 PyGithub-2.6.1 pynacl-1.5.0\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \n",
            "\u001b[32m'matrix-\u001b[0m\u001b[32mclient\u001b[0m\u001b[32m==0.4.0'\u001b[0m\u001b[1m]\u001b[0m\n",
            "Collecting matrix-client==0.4.0\n",
            "  Downloading matrix_client-0.4.0-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: requests~=2.22 in /usr/local/lib/python3.11/dist-packages (from matrix-client==0.4.0) (2.32.3)\n",
            "Collecting urllib3~=1.21 (from matrix-client==0.4.0)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.22->matrix-client==0.4.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.22->matrix-client==0.4.0) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.22->matrix-client==0.4.0) (2025.7.9)\n",
            "Downloading matrix_client-0.4.0-py2.py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3, matrix-client\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.4.0\n",
            "    Uninstalling urllib3-2.4.0:\n",
            "      Successfully uninstalled urllib3-2.4.0\n",
            "Successfully installed matrix-client-0.4.0 urllib3-1.26.20\n",
            "\u001b[1m[\u001b[0mComfyUI-Manager\u001b[1m]\u001b[0m skip black listed pip installation: \u001b[32m'transformers'\u001b[0m\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \n",
            "\u001b[32m'huggingface-hub>0.20'\u001b[0m\u001b[1m]\u001b[0m\n",
            "Requirement already satisfied: huggingface-hub>0.20 in /usr/local/lib/python3.11/dist-packages (0.33.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>0.20) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>0.20) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>0.20) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>0.20) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>0.20) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>0.20) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>0.20) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>0.20) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>0.20) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>0.20) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>0.20) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>0.20) (2025.7.9)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \n",
            "\u001b[32m'typer'\u001b[0m\u001b[1m]\u001b[0m\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.11/dist-packages (0.16.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer) (8.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from typer) (4.14.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer) (0.1.2)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \n",
            "\u001b[32m'rich'\u001b[0m\u001b[1m]\u001b[0m\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \n",
            "\u001b[32m'typing-extensions'\u001b[0m\u001b[1m]\u001b[0m\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (4.14.1)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \n",
            "\u001b[32m'toml'\u001b[0m\u001b[1m]\u001b[0m\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \n",
            "\u001b[32m'uv'\u001b[0m\u001b[1m]\u001b[0m\n",
            "Collecting uv\n",
            "  Downloading uv-0.7.20-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading uv-0.7.20-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.4/18.4 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uv\n",
            "Successfully installed uv-0.7.20\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => \u001b[1m[\u001b[0m\u001b[32m'/usr/bin/python3'\u001b[0m, \u001b[32m'-m'\u001b[0m, \u001b[32m'pip'\u001b[0m, \u001b[32m'install'\u001b[0m, \n",
            "\u001b[32m'chardet'\u001b[0m\u001b[1m]\u001b[0m\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (5.2.0)\n"
          ]
        }
      ],
      "source": [
        "# #@title Environment Setup\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "OPTIONS = {}\n",
        "\n",
        "USE_GOOGLE_DRIVE = True  #@param {type:\"boolean\"}\n",
        "UPDATE_COMFY_UI = True  #@param {type:\"boolean\"}\n",
        "USE_COMFYUI_MANAGER = True  #@param {type:\"boolean\"}\n",
        "INSTALL_CUSTOM_NODES_DEPENDENCIES = True  #@param {type:\"boolean\"}\n",
        "OPTIONS['USE_GOOGLE_DRIVE'] = USE_GOOGLE_DRIVE\n",
        "OPTIONS['UPDATE_COMFY_UI'] = UPDATE_COMFY_UI\n",
        "OPTIONS['USE_COMFYUI_MANAGER'] = USE_COMFYUI_MANAGER\n",
        "OPTIONS['INSTALL_CUSTOM_NODES_DEPENDENCIES'] = INSTALL_CUSTOM_NODES_DEPENDENCIES\n",
        "\n",
        "current_dir = !pwd\n",
        "WORKSPACE = f\"{current_dir[0]}/ComfyUI\"\n",
        "\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    !echo \"Mounting Google Drive...\"\n",
        "    %cd /\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "![ ! -d $WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/comfyanonymous/ComfyUI\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['UPDATE_COMFY_UI']:\n",
        "  !echo -= Updating ComfyUI =-\n",
        "\n",
        "  # Correction of the issue of permissions being deleted on Google Drive.\n",
        "  ![ -f \".ci/nightly/update_windows/update_comfyui_and_python_dependencies.bat\" ] && chmod 755 .ci/nightly/update_windows/update_comfyui_and_python_dependencies.bat\n",
        "  ![ -f \".ci/nightly/windows_base_files/run_nvidia_gpu.bat\" ] && chmod 755 .ci/nightly/windows_base_files/run_nvidia_gpu.bat\n",
        "  ![ -f \".ci/update_windows/update_comfyui_and_python_dependencies.bat\" ] && chmod 755 .ci/update_windows/update_comfyui_and_python_dependencies.bat\n",
        "  ![ -f \".ci/update_windows_cu118/update_comfyui_and_python_dependencies.bat\" ] && chmod 755 .ci/update_windows_cu118/update_comfyui_and_python_dependencies.bat\n",
        "  ![ -f \".ci/update_windows/update.py\" ] && chmod 755 .ci/update_windows/update.py\n",
        "  ![ -f \".ci/update_windows/update_comfyui.bat\" ] && chmod 755 .ci/update_windows/update_comfyui.bat\n",
        "  ![ -f \".ci/update_windows/README_VERY_IMPORTANT.txt\" ] && chmod 755 .ci/update_windows/README_VERY_IMPORTANT.txt\n",
        "  ![ -f \".ci/update_windows/run_cpu.bat\" ] && chmod 755 .ci/update_windows/run_cpu.bat\n",
        "  ![ -f \".ci/update_windows/run_nvidia_gpu.bat\" ] && chmod 755 .ci/update_windows/run_nvidia_gpu.bat\n",
        "\n",
        "  !git pull\n",
        "\n",
        "!echo -= Install dependencies =-\n",
        "!pip3 install accelerate\n",
        "!pip3 install einops transformers>=4.28.1 safetensors>=0.4.2 aiohttp pyyaml Pillow scipy tqdm psutil tokenizers>=0.13.3\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip3 install torchsde\n",
        "!pip3 install kornia>=0.7.1 spandrel soundfile sentencepiece\n",
        "\n",
        "if OPTIONS['USE_COMFYUI_MANAGER']:\n",
        "  %cd custom_nodes\n",
        "\n",
        "  # Correction of the issue of permissions being deleted on Google Drive.\n",
        "  ![ -f \"ComfyUI-Manager/check.sh\" ] && chmod 755 ComfyUI-Manager/check.sh\n",
        "  ![ -f \"ComfyUI-Manager/scan.sh\" ] && chmod 755 ComfyUI-Manager/scan.sh\n",
        "  ![ -f \"ComfyUI-Manager/node_db/dev/scan.sh\" ] && chmod 755 ComfyUI-Manager/node_db/dev/scan.sh\n",
        "  ![ -f \"ComfyUI-Manager/node_db/tutorial/scan.sh\" ] && chmod 755 ComfyUI-Manager/node_db/tutorial/scan.sh\n",
        "  ![ -f \"ComfyUI-Manager/scripts/install-comfyui-venv-linux.sh\" ] && chmod 755 ComfyUI-Manager/scripts/install-comfyui-venv-linux.sh\n",
        "  ![ -f \"ComfyUI-Manager/scripts/install-comfyui-venv-win.bat\" ] && chmod 755 ComfyUI-Manager/scripts/install-comfyui-venv-win.bat\n",
        "\n",
        "  ![ ! -d ComfyUI-Manager ] && echo -= Initial setup ComfyUI-Manager =- && git clone https://github.com/ltdrdata/ComfyUI-Manager\n",
        "  %cd ComfyUI-Manager\n",
        "  !git pull\n",
        "\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['INSTALL_CUSTOM_NODES_DEPENDENCIES']:\n",
        "  !echo -= Install custom nodes dependencies =-\n",
        "  !pip install GitPython\n",
        "  !python custom_nodes/ComfyUI-Manager/cm-cli.py restore-dependencies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cccccccccc"
      },
      "source": [
        "Download some models/checkpoints/vae or custom comfyui nodes (uncomment the commands for the ones you want)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dddddddddd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a76bf930-feb4-47af-f1e6-454e54b10cb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-13 18:01:34--  https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.23, 18.164.174.118, 18.164.174.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: /stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt [following]\n",
            "--2025-07-13 18:01:35--  https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\n",
            "Reusing existing connection to huggingface.co:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/66/6f/666f465fa70158515404e8de2c6bc6fe2f90c46f9296293aa14daededeb32c52/cc6cb27103417325ff94f52b7a5d2dde45a7515b25c255d8e396c90014281516?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27v1-5-pruned-emaonly.ckpt%3B+filename%3D%22v1-5-pruned-emaonly.ckpt%22%3B&Expires=1752432869&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MjQzMjg2OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82Ni82Zi82NjZmNDY1ZmE3MDE1ODUxNTQwNGU4ZGUyYzZiYzZmZTJmOTBjNDZmOTI5NjI5M2FhMTRkYWVkZWRlYjMyYzUyL2NjNmNiMjcxMDM0MTczMjVmZjk0ZjUyYjdhNWQyZGRlNDVhNzUxNWIyNWMyNTVkOGUzOTZjOTAwMTQyODE1MTY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=TRvGe65Qmib8NmkC2MDjzxwQFwdw-6Bpvkmrhxo5mGeS4bXpIxw6%7EgF0aUff1kuXluSSaBxPBivS8SUBhZHKt-Z4AZ1z7bq-zTJzwcedItEwU%7E0qQmeChu-vuXQ6vtlLwMLuWIiviUG5qFdrvCaWQBKKtYDi5YLWiuur8ia9bRLRn2I2YTcSmpCB-uyMfOQlyj569nJtXK1WgUVE4UTksv4N2ggBCoYDP6To%7EAJcGJXLd7K2xKqr36Zy9C37m27208BJbemER6OHAp83CXe7ggT6xYTlhw6X9%7EUtCl6178voPMiNziQJqpRwDAZwT84J1yGu7x6vgrP4n3gWP7p22g__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-07-13 18:01:35--  https://cdn-lfs.hf.co/repos/66/6f/666f465fa70158515404e8de2c6bc6fe2f90c46f9296293aa14daededeb32c52/cc6cb27103417325ff94f52b7a5d2dde45a7515b25c255d8e396c90014281516?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27v1-5-pruned-emaonly.ckpt%3B+filename%3D%22v1-5-pruned-emaonly.ckpt%22%3B&Expires=1752432869&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MjQzMjg2OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82Ni82Zi82NjZmNDY1ZmE3MDE1ODUxNTQwNGU4ZGUyYzZiYzZmZTJmOTBjNDZmOTI5NjI5M2FhMTRkYWVkZWRlYjMyYzUyL2NjNmNiMjcxMDM0MTczMjVmZjk0ZjUyYjdhNWQyZGRlNDVhNzUxNWIyNWMyNTVkOGUzOTZjOTAwMTQyODE1MTY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=TRvGe65Qmib8NmkC2MDjzxwQFwdw-6Bpvkmrhxo5mGeS4bXpIxw6%7EgF0aUff1kuXluSSaBxPBivS8SUBhZHKt-Z4AZ1z7bq-zTJzwcedItEwU%7E0qQmeChu-vuXQ6vtlLwMLuWIiviUG5qFdrvCaWQBKKtYDi5YLWiuur8ia9bRLRn2I2YTcSmpCB-uyMfOQlyj569nJtXK1WgUVE4UTksv4N2ggBCoYDP6To%7EAJcGJXLd7K2xKqr36Zy9C37m27208BJbemER6OHAp83CXe7ggT6xYTlhw6X9%7EUtCl6178voPMiNziQJqpRwDAZwT84J1yGu7x6vgrP4n3gWP7p22g__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.169.231.115, 3.169.231.87, 3.169.231.38, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.169.231.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4265380512 (4.0G) [binary/octet-stream]\n",
            "Saving to: ‘./models/checkpoints/v1-5-pruned-emaonly.ckpt’\n",
            "\n",
            "v1-5-pruned-emaonly 100%[===================>]   3.97G  65.3MB/s    in 61s     \n",
            "\n",
            "2025-07-13 18:02:36 (66.5 MB/s) - ‘./models/checkpoints/v1-5-pruned-emaonly.ckpt’ saved [4265380512/4265380512]\n",
            "\n",
            "--2025-07-13 18:02:37--  https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.17, 18.164.174.23, 18.164.174.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/6347df96f17980bc83f3c5b5/af70eae9c03602d0009920fcc0c389adcaec8b8e280ac6709006eb5253700649?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250713%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250713T180237Z&X-Amz-Expires=3600&X-Amz-Signature=02f2e1c57c7b2c9307037fac41c627310f647af4c496715979a23db812ccaa35&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27vae-ft-mse-840000-ema-pruned.safetensors%3B+filename%3D%22vae-ft-mse-840000-ema-pruned.safetensors%22%3B&x-id=GetObject&Expires=1752433357&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MjQzMzM1N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82MzQ3ZGY5NmYxNzk4MGJjODNmM2M1YjUvYWY3MGVhZTljMDM2MDJkMDAwOTkyMGZjYzBjMzg5YWRjYWVjOGI4ZTI4MGFjNjcwOTAwNmViNTI1MzcwMDY0OSoifV19&Signature=WSP8kKLg643mwxARHm5crhalXwy7iqtPXv1AS%7EMOerK5dIeuKgHrQ5BoU25TPFhnf0Kz16c%7E3OxiFc4O4z1MYI7mY6vtRDiutf%7En%7E3-WFJ0RLHyrXyH1KlIlbqMgl0n%7EbzizwoLO1G-k%7ERCZ%7EwWsPdT2uPzyYGO5n7NR5DYdTODIsBCpBq5Vv3l%7EMydgG3p8WLsurobzN1mcVYKYpik-hxTItJGqQ3nXNcCX4447yWAOUtEuOZq%7E8qMjNdDbRa1wwYkeMk3Pv6JhcUlKdaYQejM7BzauylLe-L6Fa9z5GQdeHOaWBzDEvK2JqHMrXB1j8WPBJ5PJsZloQn%7E1sceC3A__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-07-13 18:02:37--  https://cas-bridge.xethub.hf.co/xet-bridge-us/6347df96f17980bc83f3c5b5/af70eae9c03602d0009920fcc0c389adcaec8b8e280ac6709006eb5253700649?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250713%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250713T180237Z&X-Amz-Expires=3600&X-Amz-Signature=02f2e1c57c7b2c9307037fac41c627310f647af4c496715979a23db812ccaa35&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27vae-ft-mse-840000-ema-pruned.safetensors%3B+filename%3D%22vae-ft-mse-840000-ema-pruned.safetensors%22%3B&x-id=GetObject&Expires=1752433357&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MjQzMzM1N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82MzQ3ZGY5NmYxNzk4MGJjODNmM2M1YjUvYWY3MGVhZTljMDM2MDJkMDAwOTkyMGZjYzBjMzg5YWRjYWVjOGI4ZTI4MGFjNjcwOTAwNmViNTI1MzcwMDY0OSoifV19&Signature=WSP8kKLg643mwxARHm5crhalXwy7iqtPXv1AS%7EMOerK5dIeuKgHrQ5BoU25TPFhnf0Kz16c%7E3OxiFc4O4z1MYI7mY6vtRDiutf%7En%7E3-WFJ0RLHyrXyH1KlIlbqMgl0n%7EbzizwoLO1G-k%7ERCZ%7EwWsPdT2uPzyYGO5n7NR5DYdTODIsBCpBq5Vv3l%7EMydgG3p8WLsurobzN1mcVYKYpik-hxTItJGqQ3nXNcCX4447yWAOUtEuOZq%7E8qMjNdDbRa1wwYkeMk3Pv6JhcUlKdaYQejM7BzauylLe-L6Fa9z5GQdeHOaWBzDEvK2JqHMrXB1j8WPBJ5PJsZloQn%7E1sceC3A__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.164.174.68, 18.164.174.21, 18.164.174.4, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.164.174.68|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 334641190 (319M)\n",
            "Saving to: ‘./models/vae/vae-ft-mse-840000-ema-pruned.safetensors’\n",
            "\n",
            "vae-ft-mse-840000-e 100%[===================>] 319.14M  72.7MB/s    in 4.5s    \n",
            "\n",
            "2025-07-13 18:02:41 (71.2 MB/s) - ‘./models/vae/vae-ft-mse-840000-ema-pruned.safetensors’ saved [334641190/334641190]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Checkpoints\n",
        "\n",
        "### SDXL\n",
        "### I recommend these workflow examples: https://comfyanonymous.github.io/ComfyUI_examples/sdxl/\n",
        "\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# SDXL ReVision\n",
        "#!wget -c https://huggingface.co/comfyanonymous/clip_vision_g/resolve/main/clip_vision_g.safetensors -P ./models/clip_vision/\n",
        "\n",
        "# SD1.5\n",
        "!wget -c https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt -P ./models/checkpoints/\n",
        "\n",
        "# SD2\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Some SD1.5 anime style\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_hard.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A1_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A3_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/anything-v3-fp16-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Waifu Diffusion 1.5 (anime style SD2.x 768-v)\n",
        "#!wget -c https://huggingface.co/waifu-diffusion/wd-1-5-beta3/resolve/main/wd-illusion-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# unCLIP models\n",
        "#!wget -c https://huggingface.co/comfyanonymous/illuminatiDiffusionV1_v11_unCLIP/resolve/main/illuminatiDiffusionV1_v11-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/wd-1.5-beta2_unCLIP/resolve/main/wd-1-5-beta2-aesthetic-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# VAE\n",
        "!wget -c https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/VAEs/orangemix.vae.pt -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt -P ./models/vae/\n",
        "\n",
        "\n",
        "# Loras\n",
        "#!wget -c https://civitai.com/api/download/models/10350 -O ./models/loras/theovercomer8sContrastFix_sd21768.safetensors #theovercomer8sContrastFix SD2.x 768-v\n",
        "#!wget -c https://civitai.com/api/download/models/10638 -O ./models/loras/theovercomer8sContrastFix_sd15.safetensors #theovercomer8sContrastFix SD1.x\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors -P ./models/loras/ #SDXL offset noise lora\n",
        "\n",
        "\n",
        "# T2I-Adapter\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_seg_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_openpose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd14v1.pth -P ./models/controlnet/\n",
        "\n",
        "# T2I Styles Model\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth -P ./models/style_models/\n",
        "\n",
        "# CLIPVision model (needed for styles model)\n",
        "#!wget -c https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin -O ./models/clip_vision/clip_vit14.bin\n",
        "\n",
        "\n",
        "# ControlNet\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_canny_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_lineart_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_seg_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_softedge_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11u_sd15_tile_fp16.safetensors -P ./models/controlnet/\n",
        "\n",
        "# ControlNet SDXL\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-canny-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-depth-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-recolor-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-sketch-rank256.safetensors -P ./models/controlnet/\n",
        "\n",
        "# Controlnet Preprocessor nodes by Fannovel16\n",
        "#!cd custom_nodes && git clone https://github.com/Fannovel16/comfy_controlnet_preprocessors; cd comfy_controlnet_preprocessors && python install.py\n",
        "\n",
        "\n",
        "# GLIGEN\n",
        "#!wget -c https://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/resolve/main/gligen_sd14_textbox_pruned_fp16.safetensors -P ./models/gligen/\n",
        "\n",
        "\n",
        "# ESRGAN upscale model\n",
        "#!wget -c https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth -P ./models/upscale_models/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkkk"
      },
      "source": [
        "### Run ComfyUI with cloudflared (Recommended Way)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P ~ git clone https://github.com/ltdrdata/comfyui-unsafe-torch"
      ],
      "metadata": {
        "id": "-huOwfcxQwWe",
        "outputId": "be41f8b8-6504-42b4-8f33-d4326f16dbb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-13 19:29:04--  http://git/\n",
            "Resolving git (git)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘git’\n",
            "--2025-07-13 19:29:04--  http://clone/\n",
            "Resolving clone (clone)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘clone’\n",
            "--2025-07-13 19:29:04--  https://github.com/ltdrdata/comfyui-unsafe-torch\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘/root/comfyui-unsafe-torch’\n",
            "\n",
            "comfyui-unsafe-torc     [  <=>               ] 234.60K  1016KB/s    in 0.2s    \n",
            "\n",
            "2025-07-13 19:29:05 (1016 KB/s) - ‘/root/comfyui-unsafe-torch’ saved [240233]\n",
            "\n",
            "FINISHED --2025-07-13 19:29:05--\n",
            "Total wall clock time: 0.9s\n",
            "Downloaded: 1 files, 235K in 0.2s (1016 KB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjjj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "950839c3-2e8a-4235-b0c1-466eb4bf0b44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-13 19:29:38--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2025.7.0/cloudflared-linux-amd64.deb [following]\n",
            "--2025-07-13 19:29:39--  https://github.com/cloudflare/cloudflared/releases/download/2025.7.0/cloudflared-linux-amd64.deb\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/106867604/71a18481-c0d4-48a3-92f7-c052c62a8b60?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-07-13T20%3A27%3A00Z&rscd=attachment%3B+filename%3Dcloudflared-linux-amd64.deb&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-07-13T19%3A26%3A36Z&ske=2025-07-13T20%3A27%3A00Z&sks=b&skv=2018-11-09&sig=zKL2kXunhURzMTWsYU%2F1liIYdQyGBbBUGHk9maorMrI%3D&jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1MjQzNTI3OSwibmJmIjoxNzUyNDM0OTc5LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.dJT5rOKvXM1MuetJMNYn3U5hqCbgnJmNqX2HKmEcSDY&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-07-13 19:29:39--  https://release-assets.githubusercontent.com/github-production-release-asset/106867604/71a18481-c0d4-48a3-92f7-c052c62a8b60?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-07-13T20%3A27%3A00Z&rscd=attachment%3B+filename%3Dcloudflared-linux-amd64.deb&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-07-13T19%3A26%3A36Z&ske=2025-07-13T20%3A27%3A00Z&sks=b&skv=2018-11-09&sig=zKL2kXunhURzMTWsYU%2F1liIYdQyGBbBUGHk9maorMrI%3D&jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1MjQzNTI3OSwibmJmIjoxNzUyNDM0OTc5LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.dJT5rOKvXM1MuetJMNYn3U5hqCbgnJmNqX2HKmEcSDY&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20166246 (19M) [application/octet-stream]\n",
            "Saving to: ‘/root/cloudflared-linux-amd64.deb.1’\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  19.23M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-07-13 19:29:39 (202 MB/s) - ‘/root/cloudflared-linux-amd64.deb.1’ saved [20166246/20166246]\n",
            "\n",
            "(Reading database ... 126285 files and directories currently installed.)\n",
            "Preparing to unpack .../cloudflared-linux-amd64.deb ...\n",
            "Unpacking cloudflared (2025.7.0) over (2025.7.0) ...\n",
            "Setting up cloudflared (2025.7.0) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "[START] Security scan\n",
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "[DONE] Security scan\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2025-07-13 19:29:42.046\n",
            "** Platform: Linux\n",
            "** Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/drive/MyDrive/ComfyUI\n",
            "** ComfyUI Base Folder Path: /content/drive/MyDrive/ComfyUI\n",
            "** User directory: /content/drive/MyDrive/ComfyUI/user\n",
            "** ComfyUI-Manager config path: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/config.ini\n",
            "** Log path: /content/drive/MyDrive/ComfyUI/user/comfyui.log\n",
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "pytorch version: 2.6.0+cu124\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "Checkpoint files will always be loaded safely.\n",
            "Using pytorch attention\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfystream\n",
            "   1.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "   7.8 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/agilly1989_motorway\n",
            "\n",
            "WARNING: Potential Error in code: Torch already imported, torch should never be imported before this point.\n",
            "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "ComfyUI version: 0.3.44\n",
            "ComfyUI frontend version: 1.23.4\n",
            "[Prompt Server] web root: /usr/local/lib/python3.11/dist-packages/comfyui_frontend_package/static\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Successfully imported spandrel_extra_arches: support for non commercial upscale models.\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "### Loading: ComfyUI-Manager (V3.34)\n",
            "[ComfyUI-Manager] network_mode: public\n",
            "### ComfyUI Version: v0.3.44-15-g4831e9c2 | Released on '2025-07-13'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ComfyUI/nodes.py\", line 2124, in load_custom_node\n",
            "    module_spec.loader.exec_module(module)\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfystream/__init__.py\", line 34, in <module>\n",
            "    from .nodes import NODE_CLASS_MAPPINGS, NODE_DISPLAY_NAME_MAPPINGS\n",
            "  File \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfystream/nodes/__init__.py\", line 3, in <module>\n",
            "    from .audio_utils import *\n",
            "  File \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfystream/nodes/audio_utils/__init__.py\", line 1, in <module>\n",
            "    from .load_audio_tensor import LoadAudioTensor\n",
            "  File \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfystream/nodes/audio_utils/load_audio_tensor.py\", line 3, in <module>\n",
            "    from comfystream import tensor_cache\n",
            "  File \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfystream/src/comfystream/__init__.py\", line 1, in <module>\n",
            "    from .client import ComfyStreamClient\n",
            "  File \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfystream/src/comfystream/client.py\", line 6, in <module>\n",
            "    from comfystream.utils import convert_prompt\n",
            "  File \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfystream/src/comfystream/utils.py\", line 4, in <module>\n",
            "    from comfy.api.components.schema.prompt import Prompt, PromptDictInput\n",
            "ModuleNotFoundError: No module named 'comfy.api'\n",
            "\n",
            "Cannot import /content/drive/MyDrive/ComfyUI/custom_nodes/comfystream module for custom nodes: No module named 'comfy.api'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/agilly1989_motorway\n",
            "   0.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "   0.3 seconds (IMPORT FAILED): /content/drive/MyDrive/ComfyUI/custom_nodes/comfystream\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Error importing dependencies: No module named 'alembic'\n",
            "Please install the updated requirements.txt file by running:\n",
            "/usr/bin/python3 -m pip install -r /content/drive/MyDrive/ComfyUI/requirements.txt\n",
            "If you are on the portable package you can run: update\\update_comfyui.bat to solve this problem.\n",
            "This error is happening because ComfyUI now uses a local sqlite database.\n",
            "------------------------------------------------------------------------\n",
            "********** ERROR ***********\n",
            "\n",
            "comfyui-workflow-templates is not installed.\n",
            "\n",
            "Please install the updated requirements.txt file by running:\n",
            "/usr/bin/python3 -m pip install -r /content/drive/MyDrive/ComfyUI/requirements.txt\n",
            "If you are on the portable package you can run: update\\update_comfyui.bat to solve this problem.\n",
            "\n",
            "This error is happening because the ComfyUI frontend is no longer shipped as part of the main repo but as a pip package instead.\n",
            "\n",
            "********** ERROR ***********\n",
            "comfyui-embedded-docs package not found\n",
            "------------------------------------------------------------------------\n",
            "Error importing dependencies: No module named 'alembic'\n",
            "Please install the updated requirements.txt file by running:\n",
            "/usr/bin/python3 -m pip install -r /content/drive/MyDrive/ComfyUI/requirements.txt\n",
            "If you are on the portable package you can run: update\\update_comfyui.bat to solve this problem.\n",
            "This error is happening because ComfyUI now uses a local sqlite database.\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "ComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\n",
            "\n",
            "FETCH ComfyRegistry Data: 5/91\n",
            "This is the URL to access ComfyUI: https://feb-stretch-york-faced.trycloudflare.com                                          |\n",
            "FETCH ComfyRegistry Data: 10/91\n",
            "FETCH ComfyRegistry Data: 15/91\n",
            "FETCH ComfyRegistry Data: 20/91\n",
            "FETCH ComfyRegistry Data: 25/91\n",
            "FETCH ComfyRegistry Data: 30/91\n",
            "FETCH ComfyRegistry Data: 35/91\n",
            "FETCH ComfyRegistry Data: 40/91\n",
            "FETCH ComfyRegistry Data: 45/91\n",
            "FETCH ComfyRegistry Data: 50/91\n",
            "FETCH ComfyRegistry Data: 55/91\n",
            "FETCH ComfyRegistry Data: 60/91\n",
            "FETCH ComfyRegistry Data: 65/91\n",
            "FETCH ComfyRegistry Data: 70/91\n",
            "FETCH ComfyRegistry Data: 75/91\n",
            "FETCH ComfyRegistry Data: 80/91\n",
            "FETCH ComfyRegistry Data: 85/91\n",
            "FETCH ComfyRegistry Data: 90/91\n",
            "FETCH ComfyRegistry Data [DONE]\n",
            "[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\n",
            "FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n",
            "[ComfyUI-Manager] All startup tasks have been completed.\n",
            "got prompt\n",
            "!!! Exception during processing !!! Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 427, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 270, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 244, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 232, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/nodes.py\", line 573, in load_checkpoint\n",
            "    out = comfy.sd.load_checkpoint_guess_config(ckpt_path, output_vae=True, output_clip=True, embedding_directory=folder_paths.get_folder_paths(\"embeddings\"))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/comfy/sd.py\", line 1012, in load_checkpoint_guess_config\n",
            "    sd, metadata = comfy.utils.load_torch_file(ckpt_path, return_metadata=True)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/comfy/utils.py\", line 78, in load_torch_file\n",
            "    pl_sd = torch.load(ckpt, map_location=device, weights_only=True, **torch_args)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1470, in load\n",
            "    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n",
            "_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
            "\n",
            "Prompt executed in 18.67 seconds\n",
            "[ComfyUI-Manager] Updating ComfyUI: nightly -> v0.3.44\n",
            "ComfyUI is updated to latest stable version.\n",
            "\n",
            "[ComfyUI-Manager] Queued works are completed.\n",
            "{'update-comfyui': 1}\n",
            "\n",
            "After restarting ComfyUI, please refresh the browser.\n",
            "\n",
            "Restarting... [Legacy Mode]\n",
            "\n",
            "\n",
            "Command: ['/usr/bin/python3', 'main.py', '--dont-print-server']\n",
            "[START] Security scan\n",
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "[DONE] Security scan\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2025-07-13 19:36:16.104\n",
            "** Platform: Linux\n",
            "** Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/drive/MyDrive/ComfyUI\n",
            "** ComfyUI Base Folder Path: /content/drive/MyDrive/ComfyUI\n",
            "** User directory: /content/drive/MyDrive/ComfyUI/user\n",
            "** ComfyUI-Manager config path: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/config.ini\n",
            "** Log path: /content/drive/MyDrive/ComfyUI/user/comfyui.log\n",
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "pytorch version: 2.6.0+cu124\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Checkpoint files will always be loaded safely.\n",
            "Using pytorch attention\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfystream\n",
            "   0.9 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "   7.8 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/agilly1989_motorway\n",
            "\n",
            "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "ComfyUI version: 0.3.44\n",
            "ComfyUI frontend version: 1.23.4\n",
            "[Prompt Server] web root: /usr/local/lib/python3.11/dist-packages/comfyui_frontend_package/static\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Successfully imported spandrel_extra_arches: support for non commercial upscale models.\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "### Loading: ComfyUI-Manager (V3.34)\n",
            "[ComfyUI-Manager] network_mode: public\n",
            "### ComfyUI Revision: 3645 [c5de4955] *DETACHED | Released on '2025-07-08'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ComfyUI/nodes.py\", line 2124, in load_custom_node\n",
            "    module_spec.loader.exec_module(module)\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfystream/__init__.py\", line 34, in <module>\n",
            "    from .nodes import NODE_CLASS_MAPPINGS, NODE_DISPLAY_NAME_MAPPINGS\n",
            "  File \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfystream/nodes/__init__.py\", line 3, in <module>\n",
            "    from .audio_utils import *\n",
            "  File \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfystream/nodes/audio_utils/__init__.py\", line 1, in <module>\n",
            "    from .load_audio_tensor import LoadAudioTensor\n",
            "  File \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfystream/nodes/audio_utils/load_audio_tensor.py\", line 3, in <module>\n",
            "    from comfystream import tensor_cache\n",
            "  File \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfystream/src/comfystream/__init__.py\", line 1, in <module>\n",
            "    from .client import ComfyStreamClient\n",
            "  File \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfystream/src/comfystream/client.py\", line 6, in <module>\n",
            "    from comfystream.utils import convert_prompt\n",
            "  File \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfystream/src/comfystream/utils.py\", line 4, in <module>\n",
            "    from comfy.api.components.schema.prompt import Prompt, PromptDictInput\n",
            "ModuleNotFoundError: No module named 'comfy.api'\n",
            "\n",
            "Cannot import /content/drive/MyDrive/ComfyUI/custom_nodes/comfystream module for custom nodes: No module named 'comfy.api'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "Unable to parse pyproject.toml due to lack dependency pydantic-settings, please run 'pip install -r requirements.txt': No module named 'pydantic_settings'\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/agilly1989_motorway\n",
            "   0.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "   0.3 seconds (IMPORT FAILED): /content/drive/MyDrive/ComfyUI/custom_nodes/comfystream\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Error importing dependencies: No module named 'alembic'\n",
            "Please install the updated requirements.txt file by running:\n",
            "/usr/bin/python3 -m pip install -r /content/drive/MyDrive/ComfyUI/requirements.txt\n",
            "If you are on the portable package you can run: update\\update_comfyui.bat to solve this problem.\n",
            "This error is happening because ComfyUI now uses a local sqlite database.\n",
            "------------------------------------------------------------------------\n",
            "********** ERROR ***********\n",
            "\n",
            "comfyui-workflow-templates is not installed.\n",
            "\n",
            "Please install the updated requirements.txt file by running:\n",
            "/usr/bin/python3 -m pip install -r /content/drive/MyDrive/ComfyUI/requirements.txt\n",
            "If you are on the portable package you can run: update\\update_comfyui.bat to solve this problem.\n",
            "\n",
            "This error is happening because the ComfyUI frontend is no longer shipped as part of the main repo but as a pip package instead.\n",
            "\n",
            "********** ERROR ***********\n",
            "comfyui-embedded-docs package not found\n",
            "------------------------------------------------------------------------\n",
            "Error importing dependencies: No module named 'alembic'\n",
            "Please install the updated requirements.txt file by running:\n",
            "/usr/bin/python3 -m pip install -r /content/drive/MyDrive/ComfyUI/requirements.txt\n",
            "If you are on the portable package you can run: update\\update_comfyui.bat to solve this problem.\n",
            "This error is happening because ComfyUI now uses a local sqlite database.\n",
            "------------------------------------------------------------------------\n",
            "FETCH ComfyRegistry Data: 5/91\n",
            "FETCH ComfyRegistry Data: 10/91\n",
            "FETCH ComfyRegistry Data: 15/91\n",
            "FETCH ComfyRegistry Data: 20/91\n",
            "FETCH ComfyRegistry Data: 25/91\n",
            "FETCH ComfyRegistry Data: 30/91\n",
            "FETCH ComfyRegistry Data: 35/91\n",
            "FETCH ComfyRegistry Data: 40/91\n",
            "FETCH ComfyRegistry Data: 45/91\n",
            "FETCH ComfyRegistry Data: 50/91\n",
            "FETCH ComfyRegistry Data: 55/91\n",
            "FETCH ComfyRegistry Data: 60/91\n",
            "FETCH ComfyRegistry Data: 65/91\n",
            "FETCH ComfyRegistry Data: 70/91\n",
            "FETCH ComfyRegistry Data: 75/91\n",
            "FETCH ComfyRegistry Data: 80/91\n",
            "FETCH ComfyRegistry Data: 85/91\n",
            "FETCH ComfyRegistry Data: 90/91\n",
            "FETCH ComfyRegistry Data [DONE]\n",
            "[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\n",
            "FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n",
            "[ComfyUI-Manager] All startup tasks have been completed.\n",
            "got prompt\n",
            "!!! Exception during processing !!! Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 361, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 236, in get_output_data\n",
            "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 208, in _map_node_over_list\n",
            "    process_inputs(input_dict, i)\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 197, in process_inputs\n",
            "    results.append(getattr(obj, func)(**inputs))\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/nodes.py\", line 573, in load_checkpoint\n",
            "    out = comfy.sd.load_checkpoint_guess_config(ckpt_path, output_vae=True, output_clip=True, embedding_directory=folder_paths.get_folder_paths(\"embeddings\"))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/comfy/sd.py\", line 1005, in load_checkpoint_guess_config\n",
            "    sd, metadata = comfy.utils.load_torch_file(ckpt_path, return_metadata=True)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/comfy/utils.py\", line 78, in load_torch_file\n",
            "    pl_sd = torch.load(ckpt, map_location=device, weights_only=True, **torch_args)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1470, in load\n",
            "    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n",
            "_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
            "\n",
            "Prompt executed in 18.41 seconds\n",
            "got prompt\n",
            "!!! Exception during processing !!! Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 361, in execute\n",
            "    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 236, in get_output_data\n",
            "    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 208, in _map_node_over_list\n",
            "    process_inputs(input_dict, i)\n",
            "  File \"/content/drive/MyDrive/ComfyUI/execution.py\", line 197, in process_inputs\n",
            "    results.append(getattr(obj, func)(**inputs))\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/nodes.py\", line 573, in load_checkpoint\n",
            "    out = comfy.sd.load_checkpoint_guess_config(ckpt_path, output_vae=True, output_clip=True, embedding_directory=folder_paths.get_folder_paths(\"embeddings\"))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/comfy/sd.py\", line 1005, in load_checkpoint_guess_config\n",
            "    sd, metadata = comfy.utils.load_torch_file(ckpt_path, return_metadata=True)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/ComfyUI/comfy/utils.py\", line 78, in load_torch_file\n",
            "    pl_sd = torch.load(ckpt, map_location=device, weights_only=True, **torch_args)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1470, in load\n",
            "    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n",
            "_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
            "\n",
            "Prompt executed in 17.11 seconds\n"
          ]
        }
      ],
      "source": [
        "!wget -P ~ https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i ~/cloudflared-linux-amd64.deb\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\\n\")\n",
        "\n",
        "  p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(port)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  for line in p.stderr:\n",
        "    l = line.decode()\n",
        "    if \"trycloudflare.com \" in l:\n",
        "      print(\"This is the URL to access ComfyUI:\", l[l.find(\"http\"):], end='')\n",
        "    #print(l, end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkk"
      },
      "source": [
        "### Run ComfyUI with localtunnel\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjj"
      },
      "outputs": [],
      "source": [
        "!npm install -g localtunnel\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\\n\")\n",
        "\n",
        "  print(\"The password/enpoint ip for localtunnel is:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "  p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "  for line in p.stdout:\n",
        "    print(line.decode(), end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gggggggggg"
      },
      "source": [
        "### Run ComfyUI with colab iframe (use only in case the previous way with localtunnel doesn't work)\n",
        "\n",
        "You should see the ui appear in an iframe. If you get a 403 error, it's your firefox settings or an extension that's messing things up.\n",
        "\n",
        "If you want to open it in another window use the link.\n",
        "\n",
        "Note that some UI features like live image previews won't work because the colab iframe blocks websockets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhhhhhhhhh"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "import time\n",
        "import socket\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  from google.colab import output\n",
        "  output.serve_kernel_port_as_iframe(port, height=1024)\n",
        "  print(\"to open it in a window you can open this link here:\")\n",
        "  output.serve_kernel_port_as_window(port)\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}